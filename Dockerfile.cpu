FROM ubuntu:22.04

# Install base system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3-pip \
    python3-dev \
    espeak-ng \
    git \
    libsndfile1 \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Install PyTorch CPU version and ONNX runtime
RUN pip3 install --no-cache-dir torch==2.5.1 --extra-index-url https://download.pytorch.org/whl/cpu 

# Install all other dependencies from requirements.txt
COPY requirements.txt .
RUN pip3 install --no-cache-dir -r requirements.txt

# Copy application code
COPY . /app/

# Set working directory
WORKDIR /app

# Run with Python unbuffered output for live logging
ENV PYTHONUNBUFFERED=1

# Create non-root user
RUN useradd -m -u 1000 appuser

# Create model directory
RUN mkdir -p /app/Kokoro-82M

# Download model files using huggingface-hub (try without token first)
RUN python3 -c 'from huggingface_hub import hf_hub_download; \
    try: \
        hf_hub_download("Kokoro/Kokoro-FastAPI", "Kokoro-82M/kokoro-v0_19.onnx", local_dir="/app/Kokoro-82M", local_dir_use_symlinks=False); \
    except Exception as e: \
        print(f"Error downloading model: {e}"); \
        raise'

# Set proper ownership
RUN chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# Set Python path (app first for our imports, then model dir for model imports)
ENV PYTHONPATH=/app:/app/Kokoro-82M

# Run FastAPI server with debug logging and reload
CMD ["uvicorn", "api.src.main:app", "--host", "0.0.0.0", "--port", "8880", "--log-level", "debug"]
